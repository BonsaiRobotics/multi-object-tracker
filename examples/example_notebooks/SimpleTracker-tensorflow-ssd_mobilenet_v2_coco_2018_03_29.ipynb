{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from motrackers.simple_tracker2 import Tracker\n",
    "from motrackers.utils import select_videofile, select_tfmobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "383c41cf0c0e4f0da3c5bc8d0492e400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='..', filename='', show_hidden='False')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be3d3c7a845468286f6fdbf6fa13407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='..', filename='', show_hidden='False')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b925527ce0b04e4dbc1fcb40dea2037c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='..', filename='', show_hidden='False')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_file_path = select_videofile(\"..\")\n",
    "pbtxt_file_path, tfweights_path = select_tfmobilenet(\"..\")\n",
    "display(video_file_path, pbtxt_file_path, tfweights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Object Detector Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensorflow model for Object Detection and Tracking\n",
    "\n",
    "Here, the SSD Object Detection Model is used.\n",
    "\n",
    "For more details about single shot detection (SSD), refer the following:\n",
    " - **Liu, W., Anguelov, D., Erhan, D., Szegedy, C., Reed, S., Fu, C. Y., & Berg, A. C. (2016, October). Ssd: Single shot multibox detector. In European conference on computer vision (pp. 21-37). Springer, Cham.**\n",
    " - Research paper link: https://arxiv.org/abs/1512.02325\n",
    " - The pretrained model: https://github.com/opencv/opencv/wiki/TensorFlow-Object-Detection-API#use-existing-config-file-for-your-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_info = dict(\n",
    "    config_path=pbtxt_file_path.selected,\n",
    "    model_weights_path=tfweights_path.selected,\n",
    "    object_names={0: 'background',\n",
    "                  1: 'person', 2: 'bicycle', 3: 'car', 4: 'motorcycle', 5: 'airplane', 6: 'bus',\n",
    "                  7: 'train', 8: 'truck', 9: 'boat', 10: 'traffic light', 11: 'fire hydrant',\n",
    "                  13: 'stop sign', 14: 'parking meter', 15: 'bench', 16: 'bird', 17: 'cat',\n",
    "                  18: 'dog', 19: 'horse', 20: 'sheep', 21: 'cow', 22: 'elephant', 23: 'bear',\n",
    "                  24: 'zebra', 25: 'giraffe', 27: 'backpack', 28: 'umbrella', 31: 'handbag',\n",
    "                  32: 'tie', 33: 'suitcase', 34: 'frisbee', 35: 'skis', 36: 'snowboard',\n",
    "                  37: 'sports ball', 38: 'kite', 39: 'baseball bat', 40: 'baseball glove',\n",
    "                  41: 'skateboard', 42: 'surfboard', 43: 'tennis racket', 44: 'bottle',\n",
    "                  46: 'wine glass', 47: 'cup', 48: 'fork', 49: 'knife', 50: 'spoon',\n",
    "                  51: 'bowl', 52: 'banana', 53: 'apple', 54: 'sandwich', 55: 'orange',\n",
    "                  56: 'broccoli', 57: 'carrot', 58: 'hot dog', 59: 'pizza', 60: 'donut',\n",
    "                  61: 'cake', 62: 'chair', 63: 'couch', 64: 'potted plant', 65: 'bed',\n",
    "                  67: 'dining table', 70: 'toilet', 72: 'tv', 73: 'laptop', 74: 'mouse',\n",
    "                  75: 'remote', 76: 'keyboard', 77: 'cell phone', 78: 'microwave', 79: 'oven',\n",
    "                  80: 'toaster', 81: 'sink', 82: 'refrigerator', 84: 'book', 85: 'clock',\n",
    "                  86: 'vase', 87: 'scissors', 88: 'teddy bear', 89: 'hair drier', 90: 'toothbrush'},\n",
    "    confidence_threshold=0.5,\n",
    "    threshold=0.4\n",
    ")\n",
    "\n",
    "net = cv.dnn.readNetFromTensorflow(model_info[\"model_weights_path\"], model_info[\"config_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "\n",
    "bbox_colors = {key: np.random.randint(0, 255, size=(3,)).tolist() for key in model_info['object_names'].keys()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiate the Tracker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = Tracker(max_lost=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initiate opencv video capture object\n",
    "\n",
    "The `video_src` can take two values:\n",
    "1. If `video_src=0`: OpenCV accesses the camera connected through USB\n",
    "2. If `video_src='video_file_path'`: OpenCV will access the video file at the given path (can be MP4, AVI, etc format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_src = video_file_path.selected  # 0\n",
    "cap = cv.VideoCapture(video_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start object detection and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "update() missing 1 required positional argument: 'detection_scores'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-32745b09ef15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mputText\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFONT_HERSHEY_SIMPLEX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mobjects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdetections_bbox\u001b[0m\u001b[0;34m)\u001b[0m           \u001b[0;31m# update tracker based on the newly detected objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mobjectID\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcentroid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: update() missing 1 required positional argument: 'detection_scores'"
     ]
    }
   ],
   "source": [
    "(H, W) = (None, None)  # input image height and width for the network\n",
    "writer = None\n",
    "while(True):\n",
    "    \n",
    "    ok, image = cap.read()\n",
    "    \n",
    "    if not ok:\n",
    "        print(\"Cannot read the video feed.\")\n",
    "        break\n",
    "    \n",
    "    if W is None or H is None: (H, W) = image.shape[:2]\n",
    "    \n",
    "    blob = cv.dnn.blobFromImage(image, size=(300, 300), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "    \n",
    "    detections_bbox = []     # bounding box for detections\n",
    "    boxes, confidences, classIDs = [], [], []\n",
    "    \n",
    "    for detection in detections[0, 0, :, :]:\n",
    "        classID = detection[1]\n",
    "        confidence = detection[2]\n",
    "        if confidence > model_info['confidence_threshold']:\n",
    "            box = detection[3:7] * np.array([W, H, W, H])\n",
    "            (left, top, right, bottom) = box.astype(\"int\")\n",
    "            width = right - left + 1\n",
    "            height = bottom - top + 1\n",
    "            boxes.append([int(left), int(top), int(width), int(height)])\n",
    "            confidences.append(float(confidence))\n",
    "            classIDs.append(int(classID))\n",
    "    \n",
    "    indices = cv.dnn.NMSBoxes(boxes, confidences, model_info[\"confidence_threshold\"], model_info[\"threshold\"])\n",
    "    \n",
    "    if len(indices)>0:\n",
    "        for i in indices.flatten():\n",
    "            x, y, w, h = boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]\n",
    "            detections_bbox.append((x, y, x+w, y+h))\n",
    "            clr = [int(c) for c in bbox_colors[classIDs[i]]]\n",
    "            cv.rectangle(image, (x, y), (x+w, y+h), clr, 2)\n",
    "            label = \"{}:{:.4f}\".format(model_info[\"object_names\"][classIDs[i]], confidences[i])\n",
    "            (label_width, label_height), baseLine = cv.getTextSize(label, cv.FONT_HERSHEY_SIMPLEX, 0.5, 2)\n",
    "            y_label = max(y, label_height)\n",
    "            \n",
    "            cv.rectangle(\n",
    "                image, (x, y_label-label_height),\n",
    "                (x+label_width, y_label+baseLine), (255, 255, 255), cv.FILLED\n",
    "            )\n",
    "            \n",
    "            cv.putText(image, label, (x, y_label), cv.FONT_HERSHEY_SIMPLEX, 0.5, clr, 2)\n",
    "    \n",
    "    objects = tracker.update(detections_bbox)           # update tracker based on the newly detected objects\n",
    "    \n",
    "    for (objectID, centroid) in objects.items():\n",
    "        text = \"ID {}\".format(objectID)\n",
    "        cv.putText(image, text, (centroid[0] - 10, centroid[1] - 10), cv.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0, 255, 0), 2)\n",
    "        cv.circle(image, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "        \n",
    "    cv.imshow(\"image\", image)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    if writer is None:\n",
    "        fourcc = cv.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv.VideoWriter(\"output.avi\", fourcc, 30, (W, H), True)\n",
    "    writer.write(image)\n",
    "\n",
    "writer.release()\n",
    "cap.release()\n",
    "cv.destroyWindow(\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
