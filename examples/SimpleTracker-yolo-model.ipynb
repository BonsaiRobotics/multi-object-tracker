{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from scipy.spatial import distance\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from motrackers import SimpleTracker\n",
    "from motrackers.utils import select_videofile, select_yolo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ace4c5d7c34240e19810fe9a00f49e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='..', filename='', show_hidden='False')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e455a00eb05f4b89967698f3652176ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='..', filename='', show_hidden='False')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e239011d52e44cc95ce6335c7197bde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='..', filename='', show_hidden='False')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fde3a45ba546efabfe013d9348d8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileChooser(path='..', filename='', show_hidden='False')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_file_path = select_videofile(\"..\")\n",
    "yolo_weights_path, yolo_config_path, coco_names_path = select_yolo_model(\"..\")\n",
    "display(video_file_path, yolo_weights_path, yolo_config_path, coco_names_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Object Detector Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### YOLO Object Detection and Tracking\n",
    "\n",
    "Here, the YOLO Object Detection Model is used.\n",
    "\n",
    "The pre-trained model is from following link:\n",
    " - Object detection is taken from the following work:  \n",
    "     **Redmon, J., & Farhadi, A. (2018). Yolov3: An incremental improvement. arXiv preprint arXiv:1804.02767.**\n",
    " - Research paper for YOLO object detections and its improvement can be found here: https://arxiv.org/abs/1804.02767\n",
    " - Refer the following link for more details on the network: https://pjreddie.com/darknet/yolo/\n",
    " - The weights and configuration files can be downloaded and stored in a folder.\n",
    " - Weights: https://pjreddie.com/media/files/yolov3.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolomodel = {\"config_path\":yolo_config_path.selected,\n",
    "              \"model_weights_path\":yolo_weights_path.selected,\n",
    "              \"coco_names\":coco_names_path.selected,\n",
    "              \"confidence_threshold\": 0.5,\n",
    "              \"threshold\":0.3\n",
    "             }\n",
    "\n",
    "net = cv.dnn.readNetFromDarknet(yolomodel[\"config_path\"], yolomodel[\"model_weights_path\"])\n",
    "labels = open(yolomodel[\"coco_names\"]).read().strip().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yolo_82', 'yolo_94', 'yolo_106']\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(12345)\n",
    "layer_names = net.getLayerNames()\n",
    "layer_names = [layer_names[i[0]-1] for i in net.getUnconnectedOutLayers()]\n",
    "bbox_colors = np.random.randint(0, 255, size=(len(labels), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Instantiate the Tracker Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxLost = 5   # maximum number of object losts counted when the object is being tracked\n",
    "tracker = SimpleTracker(max_lost = maxLost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initiate opencv video capture object\n",
    "\n",
    "The `video_src` can take two values:\n",
    "1. If `video_src=0`: OpenCV accesses the camera connected through USB\n",
    "2. If `video_src='video_file_path'`: OpenCV will access the video file at the given path (can be MP4, AVI, etc format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_src = video_file_path.selected #0\n",
    "cap = cv.VideoCapture(video_src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start object detection and tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot read the video feed.\n"
     ]
    }
   ],
   "source": [
    "(H, W) = (None, None)  # input image height and width for the network\n",
    "writer = None\n",
    "while(True):\n",
    "    \n",
    "    ok, image = cap.read()\n",
    "    \n",
    "    if not ok:\n",
    "        print(\"Cannot read the video feed.\")\n",
    "        break\n",
    "    \n",
    "    if W is None or H is None: (H, W) = image.shape[:2]\n",
    "    \n",
    "    blob = cv.dnn.blobFromImage(image, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    detections_layer = net.forward(layer_names)   # detect objects using object detection model\n",
    "    \n",
    "    detections_bbox = []     # bounding box for detections\n",
    "    \n",
    "    boxes, confidences, classIDs = [], [], []\n",
    "    for out in detections_layer:\n",
    "        for detection in out:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            \n",
    "            if confidence > yolomodel['confidence_threshold']:\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "                \n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "    \n",
    "    idxs = cv.dnn.NMSBoxes(boxes, confidences, yolomodel[\"confidence_threshold\"], yolomodel[\"threshold\"])\n",
    "    \n",
    "    if len(idxs)>0:\n",
    "        for i in idxs.flatten():\n",
    "            (x, y) = (boxes[i][0], boxes[i][1])\n",
    "            (w, h) = (boxes[i][2], boxes[i][3])\n",
    "            detections_bbox.append((x, y, x+w, y+h))\n",
    "            clr = [int(c) for c in bbox_colors[classIDs[i]]]\n",
    "            cv.rectangle(image, (x, y), (x+w, y+h), clr, 2)\n",
    "            cv.putText(image, \"{}: {:.4f}\".format(labels[classIDs[i]], confidences[i]),\n",
    "                      (x, y-5), cv.FONT_HERSHEY_SIMPLEX, 0.5, clr, 2)\n",
    "    \n",
    "    objects = tracker.update(detections_bbox)           # update tracker based on the newly detected objects\n",
    "    \n",
    "    for (objectID, centroid) in objects.items():\n",
    "        text = \"ID {}\".format(objectID)\n",
    "        cv.putText(image, text, (centroid[0] - 10, centroid[1] - 10), cv.FONT_HERSHEY_SIMPLEX,\n",
    "                    0.5, (0, 255, 0), 2)\n",
    "        cv.circle(image, (centroid[0], centroid[1]), 4, (0, 255, 0), -1)\n",
    "        \n",
    "    cv.imshow(\"image\", image)\n",
    "    \n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "    if writer is None:\n",
    "        fourcc = cv.VideoWriter_fourcc(*\"MJPG\")\n",
    "        writer = cv.VideoWriter(\"output.avi\", fourcc, 30, (W, H), True)\n",
    "    writer.write(image)\n",
    "writer.release()\n",
    "cap.release()\n",
    "cv.destroyWindow(\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
